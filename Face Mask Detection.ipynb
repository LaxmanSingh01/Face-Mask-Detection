{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee079dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add7edf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['without_mask', 'with_mask']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd1e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['without_mask', 'with_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec22b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.index(categories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b096b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in categories:\n",
    "    path=os.path.join('train',i)\n",
    "    \n",
    "    label=categories.index(i)\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        image_path=os.path.join(path,file)\n",
    "        img=cv2.imread(image_path)\n",
    "        img=cv2.resize(img,(224,224))\n",
    "        data.append([img,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68cbcfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1376"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dda2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we are random shuffling\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a61062",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eee6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0317bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b538d1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daf1c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Noramalization of features\n",
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64920b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "578d497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2053bb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a2c6d",
   "metadata": {},
   "source": [
    "#### Now we have our data ,the only work remaining is to train it on Mobilenet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f341a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg=VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23c7d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d17e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f345bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers[:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06fc9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in model.layers:\n",
    "    layers.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f314aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4718e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "118379ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "35/35 [==============================] - 640s 14s/step - loss: 0.6274 - accuracy: 0.6209 - val_loss: 0.4417 - val_accuracy: 0.8768\n",
      "Epoch 2/5\n",
      "35/35 [==============================] - 442s 13s/step - loss: 0.3516 - accuracy: 0.9091 - val_loss: 0.3092 - val_accuracy: 0.8986\n",
      "Epoch 3/5\n",
      "35/35 [==============================] - 438s 13s/step - loss: 0.2583 - accuracy: 0.9418 - val_loss: 0.2651 - val_accuracy: 0.9094\n",
      "Epoch 4/5\n",
      "35/35 [==============================] - 440s 13s/step - loss: 0.2157 - accuracy: 0.9482 - val_loss: 0.2193 - val_accuracy: 0.9203\n",
      "Epoch 5/5\n",
      "35/35 [==============================] - 439s 13s/step - loss: 0.1895 - accuracy: 0.9473 - val_loss: 0.1965 - val_accuracy: 0.9384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ba17526640>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "446b998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we are going to predict the values \n",
    "## For this we are making the function\n",
    "def detect_mask(image):\n",
    "    y_pred=model.predict_classes(image.reshape(1,224,224,3))\n",
    "    return y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdd1682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets test with masked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a942085",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('test/with_mask/1-with-mask.jpg')\n",
    "img=cv2.resize(img,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "640132e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_mask(img)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efe9eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for face detection through web cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a5feb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    img=cv2.resize(frame,(224,224))\n",
    "    y_pred=detect_mask(img)\n",
    "    if y_pred == 0:\n",
    "        cv2.putText(frame,'No Mask',(30,30),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,255),2)\n",
    "    if y_pred == 1:\n",
    "        cv2.putText(frame,'Mask',(30,30),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,255),2)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detector=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    points=detector.detectMultiScale(gray)\n",
    "    for (x, y, w, h) in points:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "    cv2.imshow('face',frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c7e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
